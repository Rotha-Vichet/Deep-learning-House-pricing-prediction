{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPprAEP7LqpJ564S6NEKUKp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rotha-Vichet/Deep-learning-House-pricing-prediction/blob/main/Deeplearning_housePricing_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kNwrtDXgA2tk"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import Data\n",
        "Data = pd.read_csv('https://raw.githubusercontent.com/Rotha-Vichet/Deep-learning-House-pricing-prediction/main/kc_house_data.csv')\n",
        "Data.head(5).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "UoNNI0IrBPqx",
        "outputId": "1bcf3b09-cddb-4d46-b45f-025aac5c0dc6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             0                1                2  \\\n",
              "id                  7129300520       6414100192       5631500400   \n",
              "date           20141013T000000  20141209T000000  20150225T000000   \n",
              "price                 221900.0         538000.0         180000.0   \n",
              "bedrooms                     3                3                2   \n",
              "bathrooms                  1.0             2.25              1.0   \n",
              "sqft_living               1180             2570              770   \n",
              "sqft_lot                  5650             7242            10000   \n",
              "floors                     1.0              2.0              1.0   \n",
              "waterfront                   0                0                0   \n",
              "view                         0                0                0   \n",
              "condition                    3                3                3   \n",
              "grade                        7                7                6   \n",
              "sqft_above                1180             2170              770   \n",
              "sqft_basement                0              400                0   \n",
              "yr_built                  1955             1951             1933   \n",
              "yr_renovated                 0             1991                0   \n",
              "zipcode                  98178            98125            98028   \n",
              "lat                    47.5112           47.721          47.7379   \n",
              "long                  -122.257         -122.319         -122.233   \n",
              "sqft_living15             1340             1690             2720   \n",
              "sqft_lot15                5650             7639             8062   \n",
              "\n",
              "                             3                4  \n",
              "id                  2487200875       1954400510  \n",
              "date           20141209T000000  20150218T000000  \n",
              "price                 604000.0         510000.0  \n",
              "bedrooms                     4                3  \n",
              "bathrooms                  3.0              2.0  \n",
              "sqft_living               1960             1680  \n",
              "sqft_lot                  5000             8080  \n",
              "floors                     1.0              1.0  \n",
              "waterfront                   0                0  \n",
              "view                         0                0  \n",
              "condition                    5                3  \n",
              "grade                        7                8  \n",
              "sqft_above                1050             1680  \n",
              "sqft_basement              910                0  \n",
              "yr_built                  1965             1987  \n",
              "yr_renovated                 0                0  \n",
              "zipcode                  98136            98074  \n",
              "lat                    47.5208          47.6168  \n",
              "long                  -122.393         -122.045  \n",
              "sqft_living15             1360             1800  \n",
              "sqft_lot15                5000             7503  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec5f215d-4177-4c32-b7b1-543bc311a3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>6414100192</td>\n",
              "      <td>5631500400</td>\n",
              "      <td>2487200875</td>\n",
              "      <td>1954400510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>20150218T000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>510000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living</th>\n",
              "      <td>1180</td>\n",
              "      <td>2570</td>\n",
              "      <td>770</td>\n",
              "      <td>1960</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot</th>\n",
              "      <td>5650</td>\n",
              "      <td>7242</td>\n",
              "      <td>10000</td>\n",
              "      <td>5000</td>\n",
              "      <td>8080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>floors</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>waterfront</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>view</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>condition</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grade</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_above</th>\n",
              "      <td>1180</td>\n",
              "      <td>2170</td>\n",
              "      <td>770</td>\n",
              "      <td>1050</td>\n",
              "      <td>1680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_basement</th>\n",
              "      <td>0</td>\n",
              "      <td>400</td>\n",
              "      <td>0</td>\n",
              "      <td>910</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_built</th>\n",
              "      <td>1955</td>\n",
              "      <td>1951</td>\n",
              "      <td>1933</td>\n",
              "      <td>1965</td>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yr_renovated</th>\n",
              "      <td>0</td>\n",
              "      <td>1991</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>98178</td>\n",
              "      <td>98125</td>\n",
              "      <td>98028</td>\n",
              "      <td>98136</td>\n",
              "      <td>98074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lat</th>\n",
              "      <td>47.5112</td>\n",
              "      <td>47.721</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>47.6168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>long</th>\n",
              "      <td>-122.257</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>-122.045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_living15</th>\n",
              "      <td>1340</td>\n",
              "      <td>1690</td>\n",
              "      <td>2720</td>\n",
              "      <td>1360</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sqft_lot15</th>\n",
              "      <td>5650</td>\n",
              "      <td>7639</td>\n",
              "      <td>8062</td>\n",
              "      <td>5000</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec5f215d-4177-4c32-b7b1-543bc311a3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec5f215d-4177-4c32-b7b1-543bc311a3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec5f215d-4177-4c32-b7b1-543bc311a3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get some information about Data-Set\n",
        "Data.info()\n",
        "Data.isnull().sum()\n",
        "# remove unecessary column\n",
        "Data = Data.drop('date',axis=1)\n",
        "Data = Data.drop('id',axis=1)\n",
        "Data = Data.drop('zipcode',axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "88GamF2jBf_V",
        "outputId": "5a73a61a-eca7-466d-c07e-81aa725077bf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21613 entries, 0 to 21612\n",
            "Data columns (total 21 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             21613 non-null  int64  \n",
            " 1   date           21613 non-null  object \n",
            " 2   price          21613 non-null  float64\n",
            " 3   bedrooms       21613 non-null  int64  \n",
            " 4   bathrooms      21613 non-null  float64\n",
            " 5   sqft_living    21613 non-null  int64  \n",
            " 6   sqft_lot       21613 non-null  int64  \n",
            " 7   floors         21613 non-null  float64\n",
            " 8   waterfront     21613 non-null  int64  \n",
            " 9   view           21613 non-null  int64  \n",
            " 10  condition      21613 non-null  int64  \n",
            " 11  grade          21613 non-null  int64  \n",
            " 12  sqft_above     21613 non-null  int64  \n",
            " 13  sqft_basement  21613 non-null  int64  \n",
            " 14  yr_built       21613 non-null  int64  \n",
            " 15  yr_renovated   21613 non-null  int64  \n",
            " 16  zipcode        21613 non-null  int64  \n",
            " 17  lat            21613 non-null  float64\n",
            " 18  long           21613 non-null  float64\n",
            " 19  sqft_living15  21613 non-null  int64  \n",
            " 20  sqft_lot15     21613 non-null  int64  \n",
            "dtypes: float64(5), int64(15), object(1)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = Data.drop('price',axis =1).values\n",
        "y = Data['price'].values\n",
        "#splitting Train and Test \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
      ],
      "metadata": {
        "id": "2-z7Qn5KBiuH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#standardization scaler - fit&transform on train, fit only on test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "s_scaler = StandardScaler()\n",
        "X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
        "X_test = s_scaler.transform(X_test.astype(np.float))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7F3X6flTCBzd",
        "outputId": "62a2aad5-e8cc-4637-ee56-a64b551ed71b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-71c309465cd7>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train = s_scaler.fit_transform(X_train.astype(np.float))\n",
            "<ipython-input-41-71c309465cd7>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test = s_scaler.transform(X_test.astype(np.float))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# having 19 neuron is based on the number of available features\n",
        "model = Sequential()\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(19,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='Adam',loss='mse')"
      ],
      "metadata": {
        "id": "xO8qSOfbCeti"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=128,epochs=400)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z-QHObI9Diyy",
        "outputId": "e7631241-77fc-4425-95b8-f0c8161d43c6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 425270673408.0000 - val_loss: 428820627456.0000\n",
            "Epoch 2/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 424165048320.0000 - val_loss: 424592211968.0000\n",
            "Epoch 3/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 407089315840.0000 - val_loss: 383071813632.0000\n",
            "Epoch 4/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 318778900480.0000 - val_loss: 237160726528.0000\n",
            "Epoch 5/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 160575012864.0000 - val_loss: 97610145792.0000\n",
            "Epoch 6/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 88492498944.0000 - val_loss: 75116544000.0000\n",
            "Epoch 7/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 77276028928.0000 - val_loss: 69108957184.0000\n",
            "Epoch 8/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 71787249664.0000 - val_loss: 65154912256.0000\n",
            "Epoch 9/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 67859312640.0000 - val_loss: 62032105472.0000\n",
            "Epoch 10/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 64708227072.0000 - val_loss: 59479052288.0000\n",
            "Epoch 11/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 62038999040.0000 - val_loss: 57157615616.0000\n",
            "Epoch 12/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 59661258752.0000 - val_loss: 55076696064.0000\n",
            "Epoch 13/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 57509023744.0000 - val_loss: 53130108928.0000\n",
            "Epoch 14/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 55484162048.0000 - val_loss: 51256307712.0000\n",
            "Epoch 15/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 53580288000.0000 - val_loss: 49565016064.0000\n",
            "Epoch 16/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 51645743104.0000 - val_loss: 47782756352.0000\n",
            "Epoch 17/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 49812545536.0000 - val_loss: 46125404160.0000\n",
            "Epoch 18/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 48061235200.0000 - val_loss: 44513239040.0000\n",
            "Epoch 19/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 46422130688.0000 - val_loss: 42971242496.0000\n",
            "Epoch 20/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 44812763136.0000 - val_loss: 41627840512.0000\n",
            "Epoch 21/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 43370364928.0000 - val_loss: 40269680640.0000\n",
            "Epoch 22/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 42123198464.0000 - val_loss: 39134224384.0000\n",
            "Epoch 23/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 41010380800.0000 - val_loss: 38167539712.0000\n",
            "Epoch 24/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 40054108160.0000 - val_loss: 37405057024.0000\n",
            "Epoch 25/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 39262584832.0000 - val_loss: 36803584000.0000\n",
            "Epoch 26/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 38549041152.0000 - val_loss: 36292042752.0000\n",
            "Epoch 27/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 38016077824.0000 - val_loss: 35848966144.0000\n",
            "Epoch 28/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 37594566656.0000 - val_loss: 35479179264.0000\n",
            "Epoch 29/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 37077594112.0000 - val_loss: 35141713920.0000\n",
            "Epoch 30/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 36802035712.0000 - val_loss: 34879414272.0000\n",
            "Epoch 31/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 36503179264.0000 - val_loss: 34608947200.0000\n",
            "Epoch 32/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 36150710272.0000 - val_loss: 34398371840.0000\n",
            "Epoch 33/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 35824226304.0000 - val_loss: 34259005440.0000\n",
            "Epoch 34/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 35677892608.0000 - val_loss: 34011592704.0000\n",
            "Epoch 35/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 35436982272.0000 - val_loss: 33878067200.0000\n",
            "Epoch 36/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 35315425280.0000 - val_loss: 33738223616.0000\n",
            "Epoch 37/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 35116978176.0000 - val_loss: 33570312192.0000\n",
            "Epoch 38/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 34934775808.0000 - val_loss: 33461215232.0000\n",
            "Epoch 39/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 34845569024.0000 - val_loss: 33363535872.0000\n",
            "Epoch 40/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 34744332288.0000 - val_loss: 33260931072.0000\n",
            "Epoch 41/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 34595700736.0000 - val_loss: 33164212224.0000\n",
            "Epoch 42/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 34464202752.0000 - val_loss: 33080649728.0000\n",
            "Epoch 43/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 34365329408.0000 - val_loss: 33019146240.0000\n",
            "Epoch 44/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 34309140480.0000 - val_loss: 32948076544.0000\n",
            "Epoch 45/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 34278709248.0000 - val_loss: 32913963008.0000\n",
            "Epoch 46/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 34189817856.0000 - val_loss: 32828018688.0000\n",
            "Epoch 47/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 34104979456.0000 - val_loss: 32772585472.0000\n",
            "Epoch 48/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 33970315264.0000 - val_loss: 32890548224.0000\n",
            "Epoch 49/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33922510848.0000 - val_loss: 32672481280.0000\n",
            "Epoch 50/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33853409280.0000 - val_loss: 32645103616.0000\n",
            "Epoch 51/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 33825411072.0000 - val_loss: 32635758592.0000\n",
            "Epoch 52/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 33775173632.0000 - val_loss: 32511440896.0000\n",
            "Epoch 53/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33674219520.0000 - val_loss: 32512595968.0000\n",
            "Epoch 54/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33604012032.0000 - val_loss: 32498055168.0000\n",
            "Epoch 55/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33603743744.0000 - val_loss: 32407152640.0000\n",
            "Epoch 56/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33551562752.0000 - val_loss: 32346548224.0000\n",
            "Epoch 57/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33478877184.0000 - val_loss: 32391370752.0000\n",
            "Epoch 58/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33397538816.0000 - val_loss: 32262871040.0000\n",
            "Epoch 59/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33373106176.0000 - val_loss: 32307509248.0000\n",
            "Epoch 60/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33334202368.0000 - val_loss: 32293261312.0000\n",
            "Epoch 61/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33327544320.0000 - val_loss: 32145088512.0000\n",
            "Epoch 62/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33221777408.0000 - val_loss: 32101830656.0000\n",
            "Epoch 63/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33171996672.0000 - val_loss: 32185655296.0000\n",
            "Epoch 64/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33161129984.0000 - val_loss: 32088170496.0000\n",
            "Epoch 65/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33146003456.0000 - val_loss: 31995959296.0000\n",
            "Epoch 66/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 33059528704.0000 - val_loss: 31954909184.0000\n",
            "Epoch 67/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32995051520.0000 - val_loss: 32029466624.0000\n",
            "Epoch 68/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 33047062528.0000 - val_loss: 31908042752.0000\n",
            "Epoch 69/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32985946112.0000 - val_loss: 31851026432.0000\n",
            "Epoch 70/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32899184640.0000 - val_loss: 31831330816.0000\n",
            "Epoch 71/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32844793856.0000 - val_loss: 31805669376.0000\n",
            "Epoch 72/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 32779667456.0000 - val_loss: 31889158144.0000\n",
            "Epoch 73/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32812275712.0000 - val_loss: 31714623488.0000\n",
            "Epoch 74/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32752084992.0000 - val_loss: 31704600576.0000\n",
            "Epoch 75/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32700295168.0000 - val_loss: 31662497792.0000\n",
            "Epoch 76/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 32678524928.0000 - val_loss: 31637096448.0000\n",
            "Epoch 77/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32643899392.0000 - val_loss: 31603806208.0000\n",
            "Epoch 78/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32631617536.0000 - val_loss: 31582216192.0000\n",
            "Epoch 79/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32551006208.0000 - val_loss: 31924090880.0000\n",
            "Epoch 80/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32522446848.0000 - val_loss: 31505477632.0000\n",
            "Epoch 81/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 32554534912.0000 - val_loss: 31495542784.0000\n",
            "Epoch 82/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32483768320.0000 - val_loss: 31490007040.0000\n",
            "Epoch 83/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 32448376832.0000 - val_loss: 31478857728.0000\n",
            "Epoch 84/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32410372096.0000 - val_loss: 31439587328.0000\n",
            "Epoch 85/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32346955776.0000 - val_loss: 31383416832.0000\n",
            "Epoch 86/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32336125952.0000 - val_loss: 31530788864.0000\n",
            "Epoch 87/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 32301389824.0000 - val_loss: 31380891648.0000\n",
            "Epoch 88/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32260900864.0000 - val_loss: 31283908608.0000\n",
            "Epoch 89/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32206632960.0000 - val_loss: 31268425728.0000\n",
            "Epoch 90/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32188755968.0000 - val_loss: 31240599552.0000\n",
            "Epoch 91/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 32160360448.0000 - val_loss: 31221706752.0000\n",
            "Epoch 92/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32161114112.0000 - val_loss: 31205695488.0000\n",
            "Epoch 93/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 32180209664.0000 - val_loss: 31255701504.0000\n",
            "Epoch 94/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32057944064.0000 - val_loss: 31219146752.0000\n",
            "Epoch 95/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 32030717952.0000 - val_loss: 31150897152.0000\n",
            "Epoch 96/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31980814336.0000 - val_loss: 31155283968.0000\n",
            "Epoch 97/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31994198016.0000 - val_loss: 31089215488.0000\n",
            "Epoch 98/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31913388032.0000 - val_loss: 31063056384.0000\n",
            "Epoch 99/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31898118144.0000 - val_loss: 31029071872.0000\n",
            "Epoch 100/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31842938880.0000 - val_loss: 31024158720.0000\n",
            "Epoch 101/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31870484480.0000 - val_loss: 30974736384.0000\n",
            "Epoch 102/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31819347968.0000 - val_loss: 30959724544.0000\n",
            "Epoch 103/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31795183616.0000 - val_loss: 30964645888.0000\n",
            "Epoch 104/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31742564352.0000 - val_loss: 30904864768.0000\n",
            "Epoch 105/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31737100288.0000 - val_loss: 30871623680.0000\n",
            "Epoch 106/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31664582656.0000 - val_loss: 30931988480.0000\n",
            "Epoch 107/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31605897216.0000 - val_loss: 30896234496.0000\n",
            "Epoch 108/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31614097408.0000 - val_loss: 30792452096.0000\n",
            "Epoch 109/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31583588352.0000 - val_loss: 30771470336.0000\n",
            "Epoch 110/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31560011776.0000 - val_loss: 30812456960.0000\n",
            "Epoch 111/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31548387328.0000 - val_loss: 30830884864.0000\n",
            "Epoch 112/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31520897024.0000 - val_loss: 30717726720.0000\n",
            "Epoch 113/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31465693184.0000 - val_loss: 30714324992.0000\n",
            "Epoch 114/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31451912192.0000 - val_loss: 30683228160.0000\n",
            "Epoch 115/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31390617600.0000 - val_loss: 30698893312.0000\n",
            "Epoch 116/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31408193536.0000 - val_loss: 30641457152.0000\n",
            "Epoch 117/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31363461120.0000 - val_loss: 30582835200.0000\n",
            "Epoch 118/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31351445504.0000 - val_loss: 30575859712.0000\n",
            "Epoch 119/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31274543104.0000 - val_loss: 30605092864.0000\n",
            "Epoch 120/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31183921152.0000 - val_loss: 30890113024.0000\n",
            "Epoch 121/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31291291648.0000 - val_loss: 30560909312.0000\n",
            "Epoch 122/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31193423872.0000 - val_loss: 30519769088.0000\n",
            "Epoch 123/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 31225522176.0000 - val_loss: 30505242624.0000\n",
            "Epoch 124/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31129540608.0000 - val_loss: 30498254848.0000\n",
            "Epoch 125/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31123879936.0000 - val_loss: 30499964928.0000\n",
            "Epoch 126/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31162832896.0000 - val_loss: 30412552192.0000\n",
            "Epoch 127/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 31094196224.0000 - val_loss: 30422878208.0000\n",
            "Epoch 128/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31081607168.0000 - val_loss: 30341857280.0000\n",
            "Epoch 129/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31092985856.0000 - val_loss: 30316406784.0000\n",
            "Epoch 130/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30991849472.0000 - val_loss: 30302089216.0000\n",
            "Epoch 131/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31007193088.0000 - val_loss: 30275270656.0000\n",
            "Epoch 132/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30985689088.0000 - val_loss: 30268397568.0000\n",
            "Epoch 133/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 31003707392.0000 - val_loss: 30201939968.0000\n",
            "Epoch 134/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30896234496.0000 - val_loss: 30186067968.0000\n",
            "Epoch 135/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30899714048.0000 - val_loss: 30172909568.0000\n",
            "Epoch 136/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30872797184.0000 - val_loss: 30158909440.0000\n",
            "Epoch 137/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30828449792.0000 - val_loss: 30173542400.0000\n",
            "Epoch 138/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30766108672.0000 - val_loss: 30159079424.0000\n",
            "Epoch 139/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30743361536.0000 - val_loss: 30167222272.0000\n",
            "Epoch 140/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30911309824.0000 - val_loss: 30022514688.0000\n",
            "Epoch 141/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30689056768.0000 - val_loss: 30041040896.0000\n",
            "Epoch 142/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30696087552.0000 - val_loss: 30015961088.0000\n",
            "Epoch 143/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30685763584.0000 - val_loss: 29989173248.0000\n",
            "Epoch 144/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30628081664.0000 - val_loss: 30004416512.0000\n",
            "Epoch 145/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30634602496.0000 - val_loss: 29974886400.0000\n",
            "Epoch 146/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30618806272.0000 - val_loss: 29949450240.0000\n",
            "Epoch 147/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30614024192.0000 - val_loss: 29940205568.0000\n",
            "Epoch 148/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30555541504.0000 - val_loss: 29892030464.0000\n",
            "Epoch 149/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30538835968.0000 - val_loss: 29886783488.0000\n",
            "Epoch 150/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30538240000.0000 - val_loss: 29879508992.0000\n",
            "Epoch 151/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30500984832.0000 - val_loss: 29860554752.0000\n",
            "Epoch 152/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30503643136.0000 - val_loss: 29838489600.0000\n",
            "Epoch 153/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30483144704.0000 - val_loss: 29822693376.0000\n",
            "Epoch 154/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30438739968.0000 - val_loss: 29815558144.0000\n",
            "Epoch 155/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30435883008.0000 - val_loss: 29799763968.0000\n",
            "Epoch 156/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30378610688.0000 - val_loss: 29771350016.0000\n",
            "Epoch 157/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30390423552.0000 - val_loss: 29821204480.0000\n",
            "Epoch 158/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30353528832.0000 - val_loss: 29750607872.0000\n",
            "Epoch 159/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30353823744.0000 - val_loss: 29722324992.0000\n",
            "Epoch 160/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30328498176.0000 - val_loss: 29702615040.0000\n",
            "Epoch 161/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30311800832.0000 - val_loss: 29708679168.0000\n",
            "Epoch 162/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30289414144.0000 - val_loss: 29689935872.0000\n",
            "Epoch 163/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30280855552.0000 - val_loss: 29672890368.0000\n",
            "Epoch 164/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30294900736.0000 - val_loss: 29641664512.0000\n",
            "Epoch 165/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30245236736.0000 - val_loss: 29634633728.0000\n",
            "Epoch 166/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30190729216.0000 - val_loss: 29757868032.0000\n",
            "Epoch 167/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30221918208.0000 - val_loss: 29607337984.0000\n",
            "Epoch 168/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30194012160.0000 - val_loss: 29602627584.0000\n",
            "Epoch 169/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30164955136.0000 - val_loss: 29590306816.0000\n",
            "Epoch 170/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30216525824.0000 - val_loss: 29585639424.0000\n",
            "Epoch 171/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30184054784.0000 - val_loss: 29560973312.0000\n",
            "Epoch 172/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30095812608.0000 - val_loss: 29550448640.0000\n",
            "Epoch 173/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30156283904.0000 - val_loss: 29552474112.0000\n",
            "Epoch 174/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30093688832.0000 - val_loss: 29537871872.0000\n",
            "Epoch 175/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30075252736.0000 - val_loss: 29506893824.0000\n",
            "Epoch 176/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30097358848.0000 - val_loss: 29501509632.0000\n",
            "Epoch 177/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30030059520.0000 - val_loss: 29501407232.0000\n",
            "Epoch 178/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30041298944.0000 - val_loss: 29565159424.0000\n",
            "Epoch 179/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 30096902144.0000 - val_loss: 29441937408.0000\n",
            "Epoch 180/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 30015275008.0000 - val_loss: 29569325056.0000\n",
            "Epoch 181/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29995436032.0000 - val_loss: 29400879104.0000\n",
            "Epoch 182/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29985957888.0000 - val_loss: 29402509312.0000\n",
            "Epoch 183/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29980385280.0000 - val_loss: 29400731648.0000\n",
            "Epoch 184/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29934372864.0000 - val_loss: 29380499456.0000\n",
            "Epoch 185/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29925718016.0000 - val_loss: 29428598784.0000\n",
            "Epoch 186/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29909743616.0000 - val_loss: 29379862528.0000\n",
            "Epoch 187/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29913032704.0000 - val_loss: 29504909312.0000\n",
            "Epoch 188/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29871974400.0000 - val_loss: 29529776128.0000\n",
            "Epoch 189/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29845282816.0000 - val_loss: 29365905408.0000\n",
            "Epoch 190/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29877989376.0000 - val_loss: 29360474112.0000\n",
            "Epoch 191/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29879009280.0000 - val_loss: 29384847360.0000\n",
            "Epoch 192/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29821530112.0000 - val_loss: 29301972992.0000\n",
            "Epoch 193/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29817335808.0000 - val_loss: 29283020800.0000\n",
            "Epoch 194/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29821605888.0000 - val_loss: 29273387008.0000\n",
            "Epoch 195/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 29780242432.0000 - val_loss: 29278038016.0000\n",
            "Epoch 196/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 29745848320.0000 - val_loss: 29408104448.0000\n",
            "Epoch 197/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29781338112.0000 - val_loss: 29232574464.0000\n",
            "Epoch 198/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 29748031488.0000 - val_loss: 29230651392.0000\n",
            "Epoch 199/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29716604928.0000 - val_loss: 29220161536.0000\n",
            "Epoch 200/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29764352000.0000 - val_loss: 29198245888.0000\n",
            "Epoch 201/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 29669234688.0000 - val_loss: 29223952384.0000\n",
            "Epoch 202/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29683531776.0000 - val_loss: 29258946560.0000\n",
            "Epoch 203/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29809387520.0000 - val_loss: 29180012544.0000\n",
            "Epoch 204/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29704169472.0000 - val_loss: 29176946688.0000\n",
            "Epoch 205/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29687724032.0000 - val_loss: 29204365312.0000\n",
            "Epoch 206/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29672431616.0000 - val_loss: 29131384832.0000\n",
            "Epoch 207/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29622538240.0000 - val_loss: 29140578304.0000\n",
            "Epoch 208/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29612613632.0000 - val_loss: 29106749440.0000\n",
            "Epoch 209/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29611915264.0000 - val_loss: 29091702784.0000\n",
            "Epoch 210/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29592166400.0000 - val_loss: 29129545728.0000\n",
            "Epoch 211/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29622269952.0000 - val_loss: 29119207424.0000\n",
            "Epoch 212/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29585412096.0000 - val_loss: 29068150784.0000\n",
            "Epoch 213/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29600509952.0000 - val_loss: 29059735552.0000\n",
            "Epoch 214/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29566507008.0000 - val_loss: 29059704832.0000\n",
            "Epoch 215/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29574785024.0000 - val_loss: 29035923456.0000\n",
            "Epoch 216/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 29530798080.0000 - val_loss: 29026781184.0000\n",
            "Epoch 217/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 29547212800.0000 - val_loss: 29007441920.0000\n",
            "Epoch 218/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 29490710528.0000 - val_loss: 29005617152.0000\n",
            "Epoch 219/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 29514756096.0000 - val_loss: 28974249984.0000\n",
            "Epoch 220/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 29450848256.0000 - val_loss: 29134163968.0000\n",
            "Epoch 221/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29474979840.0000 - val_loss: 29010675712.0000\n",
            "Epoch 222/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29460180992.0000 - val_loss: 28959213568.0000\n",
            "Epoch 223/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29487026176.0000 - val_loss: 28942682112.0000\n",
            "Epoch 224/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29424175104.0000 - val_loss: 28952549376.0000\n",
            "Epoch 225/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29457876992.0000 - val_loss: 28933967872.0000\n",
            "Epoch 226/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29384407040.0000 - val_loss: 28946806784.0000\n",
            "Epoch 227/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29367709696.0000 - val_loss: 28987990016.0000\n",
            "Epoch 228/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29396520960.0000 - val_loss: 28953231360.0000\n",
            "Epoch 229/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29401597952.0000 - val_loss: 28933263360.0000\n",
            "Epoch 230/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29352130560.0000 - val_loss: 28911906816.0000\n",
            "Epoch 231/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29374029824.0000 - val_loss: 28882219008.0000\n",
            "Epoch 232/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29401948160.0000 - val_loss: 28848523264.0000\n",
            "Epoch 233/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29341466624.0000 - val_loss: 28852797440.0000\n",
            "Epoch 234/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29381615616.0000 - val_loss: 28877148160.0000\n",
            "Epoch 235/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29282234368.0000 - val_loss: 28825772032.0000\n",
            "Epoch 236/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29310621696.0000 - val_loss: 28833914880.0000\n",
            "Epoch 237/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29317160960.0000 - val_loss: 28841271296.0000\n",
            "Epoch 238/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29262299136.0000 - val_loss: 28804487168.0000\n",
            "Epoch 239/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29259552768.0000 - val_loss: 28795029504.0000\n",
            "Epoch 240/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29267853312.0000 - val_loss: 28808536064.0000\n",
            "Epoch 241/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29247975424.0000 - val_loss: 28782776320.0000\n",
            "Epoch 242/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29227020288.0000 - val_loss: 28776214528.0000\n",
            "Epoch 243/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29264201728.0000 - val_loss: 28802185216.0000\n",
            "Epoch 244/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29242085376.0000 - val_loss: 28744077312.0000\n",
            "Epoch 245/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 29204199424.0000 - val_loss: 28733298688.0000\n",
            "Epoch 246/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29216247808.0000 - val_loss: 28742123520.0000\n",
            "Epoch 247/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29258289152.0000 - val_loss: 28700143616.0000\n",
            "Epoch 248/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29212641280.0000 - val_loss: 28710682624.0000\n",
            "Epoch 249/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29173735424.0000 - val_loss: 28680527872.0000\n",
            "Epoch 250/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 29197058048.0000 - val_loss: 28712671232.0000\n",
            "Epoch 251/400\n",
            "114/114 [==============================] - 1s 7ms/step - loss: 29136930816.0000 - val_loss: 28656885760.0000\n",
            "Epoch 252/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29135644672.0000 - val_loss: 28676202496.0000\n",
            "Epoch 253/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29128267776.0000 - val_loss: 28620056576.0000\n",
            "Epoch 254/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29111934976.0000 - val_loss: 28723318784.0000\n",
            "Epoch 255/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29158156288.0000 - val_loss: 28635097088.0000\n",
            "Epoch 256/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 29094246400.0000 - val_loss: 28603531264.0000\n",
            "Epoch 257/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29075159040.0000 - val_loss: 28599449600.0000\n",
            "Epoch 258/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29038792704.0000 - val_loss: 28940251136.0000\n",
            "Epoch 259/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29084119040.0000 - val_loss: 28556584960.0000\n",
            "Epoch 260/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29044164608.0000 - val_loss: 28559347712.0000\n",
            "Epoch 261/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 29030772736.0000 - val_loss: 28565037056.0000\n",
            "Epoch 262/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28989462528.0000 - val_loss: 28552206336.0000\n",
            "Epoch 263/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 29051000832.0000 - val_loss: 28517025792.0000\n",
            "Epoch 264/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28998496256.0000 - val_loss: 28492920832.0000\n",
            "Epoch 265/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28990208000.0000 - val_loss: 28477685760.0000\n",
            "Epoch 266/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28980434944.0000 - val_loss: 28476575744.0000\n",
            "Epoch 267/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28961781760.0000 - val_loss: 28506062848.0000\n",
            "Epoch 268/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28974110720.0000 - val_loss: 28469055488.0000\n",
            "Epoch 269/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28951697408.0000 - val_loss: 28446044160.0000\n",
            "Epoch 270/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28911458304.0000 - val_loss: 28462727168.0000\n",
            "Epoch 271/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28970516480.0000 - val_loss: 28481949696.0000\n",
            "Epoch 272/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28912771072.0000 - val_loss: 28414664704.0000\n",
            "Epoch 273/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28888829952.0000 - val_loss: 28419633152.0000\n",
            "Epoch 274/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 28911443968.0000 - val_loss: 28403410944.0000\n",
            "Epoch 275/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28860276736.0000 - val_loss: 28369188864.0000\n",
            "Epoch 276/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28920395776.0000 - val_loss: 28383148032.0000\n",
            "Epoch 277/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28839524352.0000 - val_loss: 28482674688.0000\n",
            "Epoch 278/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28875079680.0000 - val_loss: 28329822208.0000\n",
            "Epoch 279/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28868995072.0000 - val_loss: 28319887360.0000\n",
            "Epoch 280/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28819519488.0000 - val_loss: 28303593472.0000\n",
            "Epoch 281/400\n",
            "114/114 [==============================] - 1s 7ms/step - loss: 28818698240.0000 - val_loss: 28279066624.0000\n",
            "Epoch 282/400\n",
            "114/114 [==============================] - 1s 9ms/step - loss: 28773857280.0000 - val_loss: 28350408704.0000\n",
            "Epoch 283/400\n",
            "114/114 [==============================] - 1s 9ms/step - loss: 28815585280.0000 - val_loss: 28296767488.0000\n",
            "Epoch 284/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28772605952.0000 - val_loss: 28310456320.0000\n",
            "Epoch 285/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28755281920.0000 - val_loss: 28258248704.0000\n",
            "Epoch 286/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28828858368.0000 - val_loss: 28251738112.0000\n",
            "Epoch 287/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28809138176.0000 - val_loss: 28228042752.0000\n",
            "Epoch 288/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28774111232.0000 - val_loss: 28194123776.0000\n",
            "Epoch 289/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28740515840.0000 - val_loss: 28183762944.0000\n",
            "Epoch 290/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 28732033024.0000 - val_loss: 28172498944.0000\n",
            "Epoch 291/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28722458624.0000 - val_loss: 28349540352.0000\n",
            "Epoch 292/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28727758848.0000 - val_loss: 28199303168.0000\n",
            "Epoch 293/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28731230208.0000 - val_loss: 28128811008.0000\n",
            "Epoch 294/400\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 28719757312.0000 - val_loss: 28207558656.0000\n",
            "Epoch 295/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28655261696.0000 - val_loss: 28115869696.0000\n",
            "Epoch 296/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28656472064.0000 - val_loss: 28098525184.0000\n",
            "Epoch 297/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28688619520.0000 - val_loss: 28084025344.0000\n",
            "Epoch 298/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28629538816.0000 - val_loss: 28092715008.0000\n",
            "Epoch 299/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28656453632.0000 - val_loss: 28068087808.0000\n",
            "Epoch 300/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28629518336.0000 - val_loss: 28055119872.0000\n",
            "Epoch 301/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28655562752.0000 - val_loss: 28060383232.0000\n",
            "Epoch 302/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28643975168.0000 - val_loss: 28033554432.0000\n",
            "Epoch 303/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28576563200.0000 - val_loss: 28013772800.0000\n",
            "Epoch 304/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28591294464.0000 - val_loss: 27996248064.0000\n",
            "Epoch 305/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28593481728.0000 - val_loss: 28029614080.0000\n",
            "Epoch 306/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28554909696.0000 - val_loss: 27973720064.0000\n",
            "Epoch 307/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28507731968.0000 - val_loss: 27990204416.0000\n",
            "Epoch 308/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28596959232.0000 - val_loss: 27954565120.0000\n",
            "Epoch 309/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28553775104.0000 - val_loss: 27945000960.0000\n",
            "Epoch 310/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28544702464.0000 - val_loss: 27914426368.0000\n",
            "Epoch 311/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28535261184.0000 - val_loss: 27952027648.0000\n",
            "Epoch 312/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28512503808.0000 - val_loss: 27924955136.0000\n",
            "Epoch 313/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28534786048.0000 - val_loss: 27938617344.0000\n",
            "Epoch 314/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28474566656.0000 - val_loss: 27880448000.0000\n",
            "Epoch 315/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28463271936.0000 - val_loss: 27908055040.0000\n",
            "Epoch 316/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28483964928.0000 - val_loss: 27901536256.0000\n",
            "Epoch 317/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28438104064.0000 - val_loss: 27855257600.0000\n",
            "Epoch 318/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28449738752.0000 - val_loss: 27827980288.0000\n",
            "Epoch 319/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28423895040.0000 - val_loss: 27835432960.0000\n",
            "Epoch 320/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28425611264.0000 - val_loss: 27801231360.0000\n",
            "Epoch 321/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28418314240.0000 - val_loss: 27852460032.0000\n",
            "Epoch 322/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28398225408.0000 - val_loss: 27872204800.0000\n",
            "Epoch 323/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28431427584.0000 - val_loss: 27840659456.0000\n",
            "Epoch 324/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28408832000.0000 - val_loss: 27753650176.0000\n",
            "Epoch 325/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 28308729856.0000 - val_loss: 27934570496.0000\n",
            "Epoch 326/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28302764032.0000 - val_loss: 27758927872.0000\n",
            "Epoch 327/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28352444416.0000 - val_loss: 27712129024.0000\n",
            "Epoch 328/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28337584128.0000 - val_loss: 27835863040.0000\n",
            "Epoch 329/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28353044480.0000 - val_loss: 27700451328.0000\n",
            "Epoch 330/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28309788672.0000 - val_loss: 27725862912.0000\n",
            "Epoch 331/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28418066432.0000 - val_loss: 27677405184.0000\n",
            "Epoch 332/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28301379584.0000 - val_loss: 27664015360.0000\n",
            "Epoch 333/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28304984064.0000 - val_loss: 27661144064.0000\n",
            "Epoch 334/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28299995136.0000 - val_loss: 27642492928.0000\n",
            "Epoch 335/400\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 28268146688.0000 - val_loss: 27634710528.0000\n",
            "Epoch 336/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28271564800.0000 - val_loss: 27672424448.0000\n",
            "Epoch 337/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28294998016.0000 - val_loss: 27630938112.0000\n",
            "Epoch 338/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28245577728.0000 - val_loss: 27615029248.0000\n",
            "Epoch 339/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28235286528.0000 - val_loss: 27612182528.0000\n",
            "Epoch 340/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28270929920.0000 - val_loss: 27613085696.0000\n",
            "Epoch 341/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28292186112.0000 - val_loss: 27594133504.0000\n",
            "Epoch 342/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28182538240.0000 - val_loss: 27575799808.0000\n",
            "Epoch 343/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28254797824.0000 - val_loss: 27718864896.0000\n",
            "Epoch 344/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28199751680.0000 - val_loss: 27558053888.0000\n",
            "Epoch 345/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28205215744.0000 - val_loss: 27538581504.0000\n",
            "Epoch 346/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28186849280.0000 - val_loss: 27531986944.0000\n",
            "Epoch 347/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28147906560.0000 - val_loss: 27534309376.0000\n",
            "Epoch 348/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28149485568.0000 - val_loss: 27521636352.0000\n",
            "Epoch 349/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28143067136.0000 - val_loss: 27509407744.0000\n",
            "Epoch 350/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28100362240.0000 - val_loss: 27495186432.0000\n",
            "Epoch 351/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28119121920.0000 - val_loss: 27521161216.0000\n",
            "Epoch 352/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28116500480.0000 - val_loss: 27523153920.0000\n",
            "Epoch 353/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28114954240.0000 - val_loss: 27477970944.0000\n",
            "Epoch 354/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28070477824.0000 - val_loss: 27442245632.0000\n",
            "Epoch 355/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28074166272.0000 - val_loss: 27471208448.0000\n",
            "Epoch 356/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28076754944.0000 - val_loss: 27458320384.0000\n",
            "Epoch 357/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28044339200.0000 - val_loss: 27429482496.0000\n",
            "Epoch 358/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28052899840.0000 - val_loss: 27437365248.0000\n",
            "Epoch 359/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 28031203328.0000 - val_loss: 27456774144.0000\n",
            "Epoch 360/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28054243328.0000 - val_loss: 27504594944.0000\n",
            "Epoch 361/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28048336896.0000 - val_loss: 27403040768.0000\n",
            "Epoch 362/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28029480960.0000 - val_loss: 27382001664.0000\n",
            "Epoch 363/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 28008226816.0000 - val_loss: 27379273728.0000\n",
            "Epoch 364/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27984465920.0000 - val_loss: 27342721024.0000\n",
            "Epoch 365/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27947833344.0000 - val_loss: 27399327744.0000\n",
            "Epoch 366/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27980132352.0000 - val_loss: 27343087616.0000\n",
            "Epoch 367/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27966355456.0000 - val_loss: 27362287616.0000\n",
            "Epoch 368/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27939227648.0000 - val_loss: 27368540160.0000\n",
            "Epoch 369/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27962386432.0000 - val_loss: 27323441152.0000\n",
            "Epoch 370/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27937452032.0000 - val_loss: 27304544256.0000\n",
            "Epoch 371/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27891367936.0000 - val_loss: 27312812032.0000\n",
            "Epoch 372/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27904546816.0000 - val_loss: 27363069952.0000\n",
            "Epoch 373/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27922194432.0000 - val_loss: 27290050560.0000\n",
            "Epoch 374/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27881895936.0000 - val_loss: 27304402944.0000\n",
            "Epoch 375/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27859206144.0000 - val_loss: 27255588864.0000\n",
            "Epoch 376/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27876540416.0000 - val_loss: 27278374912.0000\n",
            "Epoch 377/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27818702848.0000 - val_loss: 27308132352.0000\n",
            "Epoch 378/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27790524416.0000 - val_loss: 27419736064.0000\n",
            "Epoch 379/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27824119808.0000 - val_loss: 27228465152.0000\n",
            "Epoch 380/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27846035456.0000 - val_loss: 27216068608.0000\n",
            "Epoch 381/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27802267648.0000 - val_loss: 27205687296.0000\n",
            "Epoch 382/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27781877760.0000 - val_loss: 27192711168.0000\n",
            "Epoch 383/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27796545536.0000 - val_loss: 27175790592.0000\n",
            "Epoch 384/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27729758208.0000 - val_loss: 27349723136.0000\n",
            "Epoch 385/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27755864064.0000 - val_loss: 27161233408.0000\n",
            "Epoch 386/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27724535808.0000 - val_loss: 27236435968.0000\n",
            "Epoch 387/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27780489216.0000 - val_loss: 27197741056.0000\n",
            "Epoch 388/400\n",
            "114/114 [==============================] - 1s 4ms/step - loss: 27735343104.0000 - val_loss: 27141601280.0000\n",
            "Epoch 389/400\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 27725656064.0000 - val_loss: 27127955456.0000\n",
            "Epoch 390/400\n",
            "114/114 [==============================] - 1s 7ms/step - loss: 27721740288.0000 - val_loss: 27120011264.0000\n",
            "Epoch 391/400\n",
            "114/114 [==============================] - 1s 9ms/step - loss: 27704983552.0000 - val_loss: 27162116096.0000\n",
            "Epoch 392/400\n",
            "114/114 [==============================] - 1s 12ms/step - loss: 27701891072.0000 - val_loss: 27104790528.0000\n",
            "Epoch 393/400\n",
            "114/114 [==============================] - 1s 8ms/step - loss: 27677411328.0000 - val_loss: 27160029184.0000\n",
            "Epoch 394/400\n",
            "114/114 [==============================] - 1s 10ms/step - loss: 27698970624.0000 - val_loss: 27106699264.0000\n",
            "Epoch 395/400\n",
            "114/114 [==============================] - 1s 10ms/step - loss: 27693920256.0000 - val_loss: 27134285824.0000\n",
            "Epoch 396/400\n",
            "114/114 [==============================] - 1s 9ms/step - loss: 27709710336.0000 - val_loss: 27144282112.0000\n",
            "Epoch 397/400\n",
            "114/114 [==============================] - 1s 12ms/step - loss: 27628742656.0000 - val_loss: 27046144000.0000\n",
            "Epoch 398/400\n",
            "114/114 [==============================] - 1s 10ms/step - loss: 27641223168.0000 - val_loss: 27048402944.0000\n",
            "Epoch 399/400\n",
            "114/114 [==============================] - 1s 10ms/step - loss: 27600957440.0000 - val_loss: 27196655616.0000\n",
            "Epoch 400/400\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 27592110080.0000 - val_loss: 27066032128.0000\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 19)                342       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 19)                380       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 19)                380       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 19)                380       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,502\n",
            "Trainable params: 1,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot(figsize=(12,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "w72zmwIzIXx2",
        "outputId": "ae09c555-13fd-4423-84e2-ade83d9e7643"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff63b7fa7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}